# -*- coding: utf-8 -*-
"""Weather_conexion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15TUtaV6KxoStFqtgJhd1aA76-uwnS6e3
"""

import os
import httpx
import pandas as pd
from pathlib import Path
from datetime import date
import asyncio 

VISUALCROSSING_API_KEY = os.getenv("VISUALCROSSING_API_KEY", "")
DATA_DIR = Path("/weather")
WEATHER_CSV = DATA_DIR / "daily_weather.csv"

# dict citys
CITY_ALIAS = {
    "PAMPLONA": "Pamplona, ES",
    "BILBAO": "Bilbao, ES",
    "BURGOS": "Burgos, ES",
    "VITORIA": "Vitoria-Gasteiz, ES",
    "ZARAGOZA": "Zaragoza, ES",
    "SAN SEBASTIAN" : "San Sebastian, ES"
}

# columns we need
WEATHER_COLUMNS = [
    "city","date","tempmax","tempmin","temp",
    "feelslikemax","feelslikemin","feelslike",
    "precip","precipprob","conditions","icon","source"
]

async def fetch_weather_for_city(city_alias: str):
    print(f"üåê [fetch_weather_for_city] Iniciando fetch para: {city_alias}")
    """Llama a Visual Crossing para city_alias (ej. 'Vitoria-Gasteiz') para 'today'."""
    if not VISUALCROSSING_API_KEY:
        raise RuntimeError("VISUALCROSSING_API_KEY no configurada")

    url = f"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/{city_alias}/today"
    params = {"unitGroup": "metric", "key": VISUALCROSSING_API_KEY, "include": "current,days"}

    async with httpx.AsyncClient(timeout=30) as client:
        r = await client.get(url, params=params)
        r.raise_for_status()
        payload = r.json()

    days = payload.get("days", [])
    print(f"üå¶Ô∏è [fetch_weather_for_city] {len(days)} d√≠as recibidos para {city_alias}")
    rows= []
    curr = payload.get("currentConditions", {}) or {}

    for day in days:
        # Build the row in CSV (con fallback a current)
        row = {
            "city": payload.get("address") or payload.get("resolvedAddress") or city_alias,
            "date": day.get("datetime") or date.today().isoformat(),
            "tempmax": day.get("tempmax"),
            "tempmin": day.get("tempmin"),
            "temp": day.get("temp") if day.get("temp") is not None else curr.get("temp"),
            "feelslikemax": day.get("feelslikemax"),
            "feelslikemin": day.get("feelslikemin"),
            "feelslike": day.get("feelslike") if day.get("feelslike") is not None else curr.get("feelslike"),
            "precip": day.get("precip"),
            "precipprob": day.get("precipprob"),
            "conditions": (curr.get("conditions") or day.get("conditions")),
            "icon": (curr.get("icon") or day.get("icon")),
            "source": "visualcrossing",
        }
        rows.append(row)
        
    print(f"‚úÖ [fetch_weather_for_city] Construidos {len(rows)} rows para {city_alias}")
    return rows

async def upsert_daily_weather_csv_async(row: dict):
    print(f"üíæ [upsert_async] Escribiendo row: {row['city']} {row['date']}")
    await asyncio.to_thread(upsert_daily_weather_csv, row)
    print("‚úÖ [upsert_async] Completado")

def upsert_daily_weather_csv(row: dict):
    """Upsert por (city, date) en data/synthetic_daily_weather.csv"""
    print("üíæ [upsert] Antes de leer CSV:", WEATHER_CSV)
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    if WEATHER_CSV.exists():
        df = pd.read_csv(WEATHER_CSV)
    else:
        df = pd.DataFrame(columns=WEATHER_COLUMNS)

    # Delete if exist (city,date)
    df = df[~((df["city"] == row["city"]) & (df["date"] == row["date"]))]

    missing = [c for c in WEATHER_COLUMNS if c not in df.columns]
    if missing:
        for c in missing:
            df[c] = None

    df = pd.concat([df, pd.DataFrame([row])[WEATHER_COLUMNS]], ignore_index=True)
    df.to_csv(WEATHER_CSV, index=False)
    print(f"‚úÖ [upsert] Escrito row: {row['city']} {row['date']} ‚Äî total filas ahora: {len(df)}")
